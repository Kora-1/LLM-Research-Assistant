""" This is the Terminal Version"""


# from graph.research_graph import build_graph
# from data.memory_utils import load_from_memory, save_to_memory
#
# if __name__ == "__main__":
#     # Prompt the user to input their research query
#     query = input("Enter your research query: ")
#
#     # Build the research graph, which will guide the process for answering the query
#     graph = build_graph()
#
#     # Step 1: Try loading the research state from memory using the query as a key
#     cached_state = load_from_memory(query)
#
#     if cached_state:
#         # If cached data is found, use it to skip the research process
#         print("Using cached research summary.")
#         result = graph.invoke(cached_state)  # Use the cached state for the result
#         print(result["final_answer"])  # Output the final answer from the cached data
#     else:
#         # Step 2: If no cached state is found, run the full agent pipeline to gather the answer
#         result = graph.invoke({"query": query})
#
#         # Step 3: Save the result to memory for future use with the same query
#         save_to_memory(result)
#
#         # Output the final answer generated by the agent pipeline
#         print("\nFinal Answer:\n")
#         print(result["final_answer"])


""" This is the Streamlit Version"""

import streamlit as st
from graph.research_graph import build_graph
from data.memory_utils import load_from_memory, save_to_memory


def main():
    # Display a title for the app
    st.title("Research Assistant with AI")

    # Input: Ask the user to provide their research query
    query = st.text_input("Enter your research query:")

    if query:
        # Display a loading spinner while the process runs
        with st.spinner('Processing your query...'):
            # Build the research graph, which defines the research and answering pipeline
            graph = build_graph()

            # Step 1: Try loading the research state from memory using the query as a key
            cached_state = load_from_memory(query)

            if cached_state:
                # If cached data is found, use it and display the result
                st.success("Using cached research summary.")
                result = graph.invoke(cached_state)
                st.write(result["final_answer"])
            else:
                # Step 2: If no cached state is found, run the full agent pipeline to gather the answer
                result = graph.invoke({"query": query})

                # Step 3: Save the result to memory for future use with the same query
                save_to_memory(result)

                # Display the final answer
                st.success("Final Answer:")
                st.write(result["final_answer"])

                # Provide an option to download the result as a JSON file
                st.download_button(
                    label="Download Result",
                    data=str(result),
                    file_name="research_result.json",
                    mime="application/json"
                )


# Run the Streamlit app
if __name__ == "__main__":
    main()

